{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujjawalsingh10/Neural-Machine-Translation/blob/main/Neural_Machine_Translation_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v-6S2_leH6tX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras.layers import InputLayer, MaxPool2D, Dense, Conv2D, Conv1D, Flatten, BatchNormalization, TextVectorization,SimpleRNN, Embedding, Input,Bidirectional, LSTM, Dropout, GRU\n",
        "from google.colab import drive\n",
        "import re\n",
        "import string\n",
        "from numpy import random\n",
        "import gensim.downloader as api\n",
        "import datetime\n",
        "from tensorboard.plugins import projector\n",
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLruSPCIIL-V"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5CtZd62IHKq",
        "outputId": "472eb33e-4a37-4c9b-ea7d-72bb33638c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-17 22:53:19--  http://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7420323 (7.1M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.08M  20.5MB/s    in 0.3s    \n",
            "\n",
            "2023-07-17 22:53:20 (20.5 MB/s) - ‘fra-eng.zip’ saved [7420323/7420323]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.manythings.org/anki/fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDU59lPvRSKP",
        "outputId": "d6e130fd-d7f6-40cd-d6b6-63f736a0b658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UUjpAiEeJzKR"
      },
      "outputs": [],
      "source": [
        "# !unzip '/content/fra-eng.zip' -d '/content/drive/MyDrive/Deep_Learning/NLP/Neural_Machine_Translation_with_RNN/dataset'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogbtVPdHLGu_"
      },
      "source": [
        "### Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rDkEx5bGKwY6"
      },
      "outputs": [],
      "source": [
        "### To convert our dataset into TensorFlow dataset types for easy manipulation\n",
        "text_dataset = tf.data.TextLineDataset('/content/drive/MyDrive/Deep_Learning/NLP/Neural_Machine_Translation_with_RNN/dataset/fra.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8KnQwRsSKEm",
        "outputId": "83a3fed8-8e28-4174-8a71-72528e172e36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Go.\\tMarche.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Go.\\tEn route !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for i in text_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z_AFK2rNbzDe"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 20000\n",
        "ENGLISH_SEQUENCE_LENGTH = 64\n",
        "FRENCH_SEQUENCE_LENGTH = 64\n",
        "EMBEDDING_DIM = 300\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "l_HGdJEcEIQT"
      },
      "outputs": [],
      "source": [
        "# ### We can check last of the elements to see what can be the max size of the sentences\n",
        "# for i in text_dataset.skip(190000):\n",
        "#   print(len(tf.strings.split(i, ' ')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "luZ3schL4yZD"
      },
      "outputs": [],
      "source": [
        "english_vectorize_layer = TextVectorization(\n",
        "    standardize = 'lower_and_strip_punctuation',\n",
        "    max_tokens = VOCAB_SIZE,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = ENGLISH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GUJywhNn5G62"
      },
      "outputs": [],
      "source": [
        "french_vectorize_layer = TextVectorization(\n",
        "    standardize = 'lower_and_strip_punctuation',\n",
        "    max_tokens = VOCAB_SIZE,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = FRENCH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL2WB226FRdt",
        "outputId": "8a3c0a01-0e81-4560-89fb-b349dcc4ca2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for i in text_dataset.take(1):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_CXKmDn5wqM"
      },
      "source": [
        "We have to create one vocabulary for English and another for Hindi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "x6END-C7FiUQ"
      },
      "outputs": [],
      "source": [
        "### We create this method to get data in x,y format and get rid of the extras z\n",
        "## We add tokens and change the dataset to 3 input type\n",
        "def selector(input_text):\n",
        "  split_text = tf.strings.split(input_text, '\\t')\n",
        "  return {'input_1' : split_text[0:1], 'input_2' : 'starttoken '+split_text[1:2] }, split_text[1:2]+' endtoken'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XpAW_9olIvMq"
      },
      "outputs": [],
      "source": [
        "split_dataset = text_dataset.map(selector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "omWbl-djTeoW"
      },
      "outputs": [],
      "source": [
        "def separator(input_text):\n",
        "  split_text = tf.strings.split(input_text, '\\t')\n",
        "  return split_text[0:1], 'starttoken '+ split_text[1:2]+ ' endtoken'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hCuouk0FT28p"
      },
      "outputs": [],
      "source": [
        "init_dataset = text_dataset.map(separator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdZ2qpXSI8UX",
        "outputId": "2aff142a-a735-4bc0-e08b-031eb498ad1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jjNci2LC5n5R"
      },
      "outputs": [],
      "source": [
        "english_training_dataset = init_dataset.map(lambda x,y : x)\n",
        "english_vectorize_layer.adapt(english_training_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4SQAKFPp76ru"
      },
      "outputs": [],
      "source": [
        "french_training_dataset = init_dataset.map(lambda x,y : y)\n",
        "french_vectorize_layer.adapt(french_training_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6-XynUHnBDvM"
      },
      "outputs": [],
      "source": [
        "# def vectorizer(english, french):\n",
        "#   return english_vectorize_layer(english), french_vectorize_layer(french)\n",
        "def vectorizer(inputs, output):\n",
        "  return {'input_1': english_vectorize_layer(inputs['input_1']),\n",
        "          'input_2': french_vectorize_layer(inputs['input_2'])}, french_vectorize_layer(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JaNRVuffBPsi"
      },
      "outputs": [],
      "source": [
        "dataset = split_dataset.map(vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8VZm4fdXPWg",
        "outputId": "8bd4106f-73e3-4bd8-ccb7-936d91eb12f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(64, 64), dtype=int64, numpy=\n",
            "array([[ 793,   63,    0, ...,    0,    0,    0],\n",
            "       [   2,  328,    0, ...,    0,    0,    0],\n",
            "       [   2, 1069,    0, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [  44,  114,    0, ...,    0,    0,    0],\n",
            "       [ 158,  431,    0, ...,    0,    0,    0],\n",
            "       [  27, 3295,    0, ...,    0,    0,    0]])>, 'input_2': <tf.Tensor: shape=(64, 64), dtype=int64, numpy=\n",
            "array([[    2,     1,    16, ...,     0,     0,     0],\n",
            "       [    2,    24,   429, ...,     0,     0,     0],\n",
            "       [    2,    24,  1483, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [    2, 10485,     0, ...,     0,     0,     0],\n",
            "       [    2,    14,    15, ...,     0,     0,     0],\n",
            "       [    2,   255,  6500, ...,     0,     0,     0]])>}, <tf.Tensor: shape=(64, 64), dtype=int64, numpy=\n",
            "array([[    1,    16,     3, ...,     0,     0,     0],\n",
            "       [   24,   429,     3, ...,     0,     0,     0],\n",
            "       [   24,  1483,     3, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [10485,     3,     0, ...,     0,     0,     0],\n",
            "       [   14,    15,  4352, ...,     0,     0,     0],\n",
            "       [  255,  6500,     3, ...,     0,     0,     0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(64, 64), dtype=int64, numpy=\n",
            "array([[  979,    62,     0, ...,     0,     0,     0],\n",
            "       [  892,     0,     0, ...,     0,     0,     0],\n",
            "       [    2,  2722,     8, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [   21, 11390,     0, ...,     0,     0,     0],\n",
            "       [   27,   311,     0, ...,     0,     0,     0],\n",
            "       [   39,  5701,     0, ...,     0,     0,     0]])>, 'input_2': <tf.Tensor: shape=(64, 64), dtype=int64, numpy=\n",
            "array([[    2,  6786,     0, ...,     0,     0,     0],\n",
            "       [    2,  3150,     0, ...,     0,     0,     0],\n",
            "       [    2, 12618,    13, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [    2,    24, 13546, ...,     0,     0,     0],\n",
            "       [    2,   262,  3231, ...,     0,     0,     0],\n",
            "       [    2,   106,    29, ...,     0,     0,     0]])>}, <tf.Tensor: shape=(64, 64), dtype=int64, numpy=\n",
            "array([[ 6786,     3,     0, ...,     0,     0,     0],\n",
            "       [ 3150,     3,     0, ...,     0,     0,     0],\n",
            "       [12618,    13,     3, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [   24, 13546,   219, ...,     0,     0,     0],\n",
            "       [  262,  3231,     3, ...,     0,     0,     0],\n",
            "       [  106,    29, 10259, ...,     0,     0,     0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(64, 64), dtype=int64, numpy=\n",
            "array([[  84,  238,    0, ...,    0,    0,    0],\n",
            "       [ 215,  944,    0, ...,    0,    0,    0],\n",
            "       [  21, 2503,    0, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [  25,  353,    0, ...,    0,    0,    0],\n",
            "       [  27,  589,    0, ...,    0,    0,    0],\n",
            "       [ 664,   31,    0, ...,    0,    0,    0]])>, 'input_2': <tf.Tensor: shape=(64, 64), dtype=int64, numpy=\n",
            "array([[   2,   34,   15, ...,    0,    0,    0],\n",
            "       [   2,   13,   15, ...,    0,    0,    0],\n",
            "       [   2,    4,   25, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   2,  201,  283, ...,    0,    0,    0],\n",
            "       [   2,  255, 2113, ...,    0,    0,    0],\n",
            "       [   2, 2803,    9, ...,    0,    0,    0]])>}, <tf.Tensor: shape=(64, 64), dtype=int64, numpy=\n",
            "array([[  34,   15,  381, ...,    0,    0,    0],\n",
            "       [  13,   15,  542, ...,    0,    0,    0],\n",
            "       [   4,   25, 1723, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 201,  283,   95, ...,    0,    0,    0],\n",
            "       [ 255, 2113,    3, ...,    0,    0,    0],\n",
            "       [2803,    9,  253, ...,    0,    0,    0]])>)\n"
          ]
        }
      ],
      "source": [
        "for i in dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqiGeX1bLyUV",
        "outputId": "2d88eb59-2dba-47f0-9460-bd196b1ad237"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('va', 'go')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "french_vectorize_layer.get_vocabulary()[104], english_vectorize_layer.get_vocabulary()[44]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCnjk0rFK0ih",
        "outputId": "1f339d58-1b94-4fb4-87a5-fce9f86c1b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2, 104,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[104,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2, 821,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[821,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2,  23, 611,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[ 23, 611,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[   2, 2727,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[2727,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[2534,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[   2, 3470,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[3470,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[2534,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[   2, 3470,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[3470,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[415,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[   2, 8105,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[8105,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[415,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[415,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[    2,   670,   198,  1771,     9,   198, 16047,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  670,   198,  1771,     9,   198, 16047,     3,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[415,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[   2, 2765,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[2765,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>)\n"
          ]
        }
      ],
      "source": [
        "for i in dataset.take(10):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1y5qprEZriG",
        "outputId": "cbe2d961-7b9b-418e-c7f8-d584421e5829"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ufTB0nIuZufn"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(buffer_size = tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEFlP7PGad-v",
        "outputId": "00bb1646-2058-408a-ee8d-691c2d6a93c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EZH0jEChPBgE"
      },
      "outputs": [],
      "source": [
        "NUM_BATCHES = int(200000/BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "EPsr-571ZVL9"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset.take(int(0.9 * NUM_BATCHES))\n",
        "val_dataset = dataset.skip(int(0.9 * NUM_BATCHES))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN93lXXAcNvE"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AejHkofsZe1p"
      },
      "outputs": [],
      "source": [
        "NUM_UNITS = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VPfvMRehfCd",
        "outputId": "3fc545da-d475-4002-d737-30930669a92d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 64, 300)      6000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 64, 300)      6000000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 512)          857088      ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    (None, 64, 512)      1250304     ['embedding_1[0][0]',            \n",
            "                                                                  'bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64, 512)      0           ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64, 20000)    10260000    ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24,367,392\n",
            "Trainable params: 24,367,392\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "## ENCODER\n",
        "input = Input(shape = (ENGLISH_SEQUENCE_LENGTH, ), dtype = 'int64', name = 'input_1')\n",
        "x = Embedding(VOCAB_SIZE, EMBEDDING_DIM, )(input)\n",
        "encoded_input = Bidirectional(GRU(NUM_UNITS, ))(x)\n",
        "\n",
        "## DECODER\n",
        "shifted_target = Input(shape = (FRENCH_SEQUENCE_LENGTH, ), dtype = 'int64', name = 'input_2')\n",
        "x = Embedding(VOCAB_SIZE, EMBEDDING_DIM, )(shifted_target)\n",
        "x = GRU(NUM_UNITS * 2, return_sequences = True)(x, initial_state = encoded_input)\n",
        "\n",
        "## OUTPUT\n",
        "x = Dropout(0.5)(x)\n",
        "target = Dense(VOCAB_SIZE, activation = 'softmax')(x)\n",
        "seq2seq_gru = Model([input, shifted_target], target)\n",
        "seq2seq_gru.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OMUjnziQjn7p"
      },
      "outputs": [],
      "source": [
        "seq2seq_gru.compile(optimizer= Adam(learning_rate= 1e-4),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy']\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Il4J1lkgsw",
        "outputId": "71dfaf36-3b41-4f54-ea41-2a6b30637b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "2812/2812 [==============================] - 579s 201ms/step - loss: 0.7470 - accuracy: 0.9123 - val_loss: 1.0439 - val_accuracy: 0.8510\n",
            "Epoch 2/15\n",
            "2812/2812 [==============================] - 560s 199ms/step - loss: 0.4731 - accuracy: 0.9268 - val_loss: 0.9280 - val_accuracy: 0.8620\n",
            "Epoch 3/15\n",
            "2812/2812 [==============================] - 498s 177ms/step - loss: 0.4062 - accuracy: 0.9337 - val_loss: 0.8478 - val_accuracy: 0.8689\n",
            "Epoch 4/15\n",
            "2812/2812 [==============================] - 496s 176ms/step - loss: 0.3638 - accuracy: 0.9379 - val_loss: 0.8051 - val_accuracy: 0.8735\n",
            "Epoch 5/15\n",
            "2812/2812 [==============================] - 495s 176ms/step - loss: 0.3328 - accuracy: 0.9410 - val_loss: 0.7693 - val_accuracy: 0.8769\n",
            "Epoch 6/15\n",
            "2812/2812 [==============================] - 495s 176ms/step - loss: 0.3089 - accuracy: 0.9436 - val_loss: 0.7414 - val_accuracy: 0.8798\n",
            "Epoch 7/15\n",
            "2812/2812 [==============================] - 496s 176ms/step - loss: 0.2890 - accuracy: 0.9459 - val_loss: 0.7195 - val_accuracy: 0.8823\n",
            "Epoch 8/15\n",
            "2812/2812 [==============================] - 494s 176ms/step - loss: 0.2720 - accuracy: 0.9479 - val_loss: 0.7068 - val_accuracy: 0.8841\n",
            "Epoch 9/15\n",
            "2812/2812 [==============================] - 496s 176ms/step - loss: 0.2574 - accuracy: 0.9497 - val_loss: 0.6835 - val_accuracy: 0.8863\n",
            "Epoch 10/15\n",
            "2812/2812 [==============================] - 495s 176ms/step - loss: 0.2446 - accuracy: 0.9513 - val_loss: 0.6745 - val_accuracy: 0.8877\n",
            "Epoch 11/15\n",
            "2812/2812 [==============================] - 495s 176ms/step - loss: 0.2333 - accuracy: 0.9529 - val_loss: 0.6653 - val_accuracy: 0.8891\n",
            "Epoch 12/15\n",
            "2812/2812 [==============================] - 498s 177ms/step - loss: 0.2232 - accuracy: 0.9543 - val_loss: 0.6565 - val_accuracy: 0.8902\n",
            "Epoch 13/15\n",
            "2812/2812 [==============================] - 497s 177ms/step - loss: 0.2140 - accuracy: 0.9555 - val_loss: 0.6466 - val_accuracy: 0.8915\n",
            "Epoch 14/15\n",
            "2812/2812 [==============================] - 495s 176ms/step - loss: 0.2055 - accuracy: 0.9568 - val_loss: 0.6387 - val_accuracy: 0.8926\n",
            "Epoch 15/15\n",
            "2812/2812 [==============================] - 493s 175ms/step - loss: 0.1978 - accuracy: 0.9579 - val_loss: 0.6361 - val_accuracy: 0.8933\n"
          ]
        }
      ],
      "source": [
        "history = seq2seq_gru.fit(train_dataset, epochs = 15, validation_data = val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ve5EtwvktQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bfb9862-232b-4b40-e76a-7677f95bb442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "seq2seq_gru.save('/content/drive/MyDrive/Deep_Learning/NLP/Neural_Machine_Translation_with_RNN/model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq_gru = tf.keras.models.load_model('/content/drive/MyDrive/Deep_Learning/NLP/Neural_Machine_Translation_with_RNN/model')"
      ],
      "metadata": {
        "id": "wgC4sWxT7ZlI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an index to word dictionary with the french vocabulary"
      ],
      "metadata": {
        "id": "FTDNl03wxsrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {x:y for x,y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n",
        "                                    french_vectorize_layer.get_vocabulary())}"
      ],
      "metadata": {
        "id": "BHvMQF5hxxss"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "K3fzT1SnnyFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translator(english_sentence):\n",
        "  tokenized_english_sentence = english_vectorize_layer([english_sentence])\n",
        "  shifted_target = 'starttoken'\n",
        "  # tokenized_french_sentence = french_vectorize_layer([shifted_target])\n",
        "\n",
        "  # output = seq2seq_gru.predict([tokenized_english_sentence, tokenized_french_sentence])\n",
        "  # french_sentence = tf.argmax(output, axis = -1)\n",
        "\n",
        "  # shifted_target = 'starttoken quels'\n",
        "  # tokenized_french_sentence = french_vectorize_layer([shifted_target])\n",
        "  # output = seq2seq_gru.predict([tokenized_english_sentence, tokenized_french_sentence])\n",
        "  # french_sentence = tf.argmax(output, axis = -1)\n",
        "\n",
        "  ### upper is the logic\n",
        "  ## To automate we will use for loop and send outputs next and repeat and stop when we find end token\n",
        "\n",
        "  for i in range(FRENCH_SEQUENCE_LENGTH):\n",
        "\n",
        "    tokenized_shifted_target = french_vectorize_layer([shifted_target])\n",
        "\n",
        "    output = seq2seq_gru.predict([tokenized_english_sentence, tokenized_shifted_target])\n",
        "    french_word_index = tf.argmax(output, axis = -1)[0][i].numpy()\n",
        "    current_word = index_to_word[french_word_index]\n",
        "\n",
        "    if current_word == 'endtoken':\n",
        "      break\n",
        "    shifted_target += ' '+ current_word\n",
        "\n",
        "    # print(shifted_target)\n",
        "\n",
        "  return shifted_target"
      ],
      "metadata": {
        "id": "pDEzetKznYLx"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### This is one hot representation of 64 words with 20000 words in voacb. we use argmax to select the highest prob words"
      ],
      "metadata": {
        "id": "7LSocYUDsng4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator(\"Roses are red Violet is blue I don't know what else to do\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "z9JFzx3wt0vf",
        "outputId": "e9a01e82-5777-40f1-9af4-845a1556edff"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'starttoken les roses sont [UNK] et je ne lai pas fait'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = {y:x for x,y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n",
        "                                    french_vectorize_layer.get_vocabulary())}"
      ],
      "metadata": {
        "id": "dsD4SpnyQtqn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index['football']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEw55QpgQ1k8",
        "outputId": "dc136ba5-8e57-4e77-9bab-bcb331b5ae55"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1181"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "french_vectorize_layer.get_vocabulary()[918], french_vectorize_layer.get_vocabulary()[49]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtB5ganiuT5n",
        "outputId": "41c97293-05f2-4312-e816-2a9705b8a2a6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('quels', 'sont')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "french_vectorize_layer.get_vocabulary()[7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TJwHxotvukm_",
        "outputId": "df331b93-4a06-42db-923f-17a5e99b2ece"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'que'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BLEU Score"
      ],
      "metadata": {
        "id": "CrkzTJCxXk2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# class BLEU(tf.keras.metrics.Metric):\n",
        "#     def __init__(self,name='bleu_score'):\n",
        "#         super(BLEU,self).__init__()\n",
        "#         self.bleu_score=0\n",
        "\n",
        "#     def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "#       y_pred=tf.argmax(y_pred,-1)\n",
        "#       self.bleu_score=0\n",
        "#       for i,j in zip(y_pred,y_true):\n",
        "#         tf.autograph.experimental.set_loop_options()\n",
        "\n",
        "#         total_words=tf.math.count_nonzero(i)\n",
        "#         total_matches=0\n",
        "#         for word in i:\n",
        "#           if word==0:\n",
        "#             break\n",
        "#           for q in range(len(j)):\n",
        "#             if j[q]==0:\n",
        "#               break\n",
        "#             if word==j[q]:\n",
        "#               total_matches+=1\n",
        "#               j=tf.boolean_mask(j,[False if y==q else True for y in range(len(j))])\n",
        "#               break\n",
        "\n",
        "#         self.bleu_score+=total_matches/total_words\n",
        "\n",
        "#     def result(self):\n",
        "#         return self.bleu_score/BATCH_SIZE"
      ],
      "metadata": {
        "id": "xy3D1sMCwqes"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!--  -->"
      ],
      "metadata": {
        "id": "0Lv5CTePdoM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# seq2seq_gru.compile(\n",
        "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "#     optimizer=tf.keras.optimizers.Adam(5e-4),)\n",
        "#     #metrics=[BLEU()],\n",
        "#     #run_eagerly=True)\n",
        ""
      ],
      "metadata": {
        "id": "Ze7rgmXgdSMB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMOFc4M2ruFO9O2CVM4X+a8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}